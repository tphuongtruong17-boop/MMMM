import { crypto, networks, opcodes, payments, script } from '@btc-vision/bitcoin';
import { Logger } from '@btc-vision/logger';
export class HashCommitmentGenerator extends Logger {
    constructor(publicKey, network = networks.bitcoin) {
        super();
        this.logColor = '#4a90d9';
        if (publicKey.length !== 33) {
            throw new Error('Public key must be 33 bytes (compressed)');
        }
        this.publicKey = publicKey;
        this.network = network;
    }
    static calculateMaxInputsPerTx() {
        const txOverhead = 40;
        const outputOverhead = 200;
        const availableWeight = HashCommitmentGenerator.MAX_STANDARD_WEIGHT - txOverhead - outputOverhead;
        return Math.floor(availableWeight / HashCommitmentGenerator.WEIGHT_PER_INPUT);
    }
    static calculateMaxDataPerTx() {
        return (HashCommitmentGenerator.calculateMaxInputsPerTx() *
            HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT *
            HashCommitmentGenerator.MAX_CHUNK_SIZE);
    }
    static estimateOutputCount(dataSize) {
        return Math.ceil(dataSize /
            (HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT *
                HashCommitmentGenerator.MAX_CHUNK_SIZE));
    }
    static estimateChunkCount(dataSize) {
        return Math.ceil(dataSize / HashCommitmentGenerator.MAX_CHUNK_SIZE);
    }
    static validateHashCommittedScript(witnessScript) {
        try {
            const decompiled = script.decompile(witnessScript);
            if (!decompiled || decompiled.length < 5) {
                return false;
            }
            const lastIdx = decompiled.length - 1;
            if (decompiled[lastIdx] !== opcodes.OP_CHECKSIG) {
                return false;
            }
            const pubkey = decompiled[lastIdx - 1];
            if (!Buffer.isBuffer(pubkey) || pubkey.length !== 33) {
                return false;
            }
            const hashParts = decompiled.slice(0, -2);
            if (hashParts.length % 3 !== 0 || hashParts.length === 0) {
                return false;
            }
            for (let i = 0; i < hashParts.length; i += 3) {
                const hash = hashParts[i + 1];
                if (hashParts[i] !== opcodes.OP_HASH160 ||
                    !Buffer.isBuffer(hash) ||
                    hash.length !== 20 ||
                    hashParts[i + 2] !== opcodes.OP_EQUALVERIFY) {
                    return false;
                }
            }
            return true;
        }
        catch {
            return false;
        }
    }
    static extractDataHashes(witnessScript) {
        try {
            const decompiled = script.decompile(witnessScript);
            if (!decompiled ||
                !HashCommitmentGenerator.validateHashCommittedScript(witnessScript)) {
                return null;
            }
            const hashParts = decompiled.slice(0, -2);
            const hashes = [];
            for (let i = 0; i < hashParts.length; i += 3) {
                hashes.push(hashParts[i + 1]);
            }
            return hashes.reverse();
        }
        catch {
            return null;
        }
    }
    static extractPublicKey(witnessScript) {
        try {
            const decompiled = script.decompile(witnessScript);
            if (!decompiled ||
                !HashCommitmentGenerator.validateHashCommittedScript(witnessScript)) {
                return null;
            }
            return decompiled[decompiled.length - 2];
        }
        catch {
            return null;
        }
    }
    static verifyChunkCommitments(dataChunks, witnessScript) {
        const committedHashes = HashCommitmentGenerator.extractDataHashes(witnessScript);
        if (!committedHashes || committedHashes.length !== dataChunks.length) {
            return false;
        }
        for (let i = 0; i < dataChunks.length; i++) {
            const actualHash = crypto.hash160(dataChunks[i]);
            if (!committedHashes[i].equals(actualHash)) {
                return false;
            }
        }
        return true;
    }
    static estimateFees(dataSize, feeRate, compressionRatio = 0.7) {
        const compressedSize = Math.ceil(dataSize * compressionRatio);
        const outputCount = HashCommitmentGenerator.estimateOutputCount(compressedSize);
        const chunkCount = HashCommitmentGenerator.estimateChunkCount(compressedSize);
        const setupInputVBytes = 2 * 58;
        const setupOutputVBytes = outputCount * 43 + 43;
        const setupOverhead = 11;
        const setupVBytes = setupOverhead + setupInputVBytes + setupOutputVBytes;
        const revealWeight = 40 + outputCount * HashCommitmentGenerator.WEIGHT_PER_INPUT + 200;
        const revealVBytes = Math.ceil(revealWeight / 4);
        const setupFee = BigInt(Math.ceil(setupVBytes * feeRate));
        const revealFee = BigInt(Math.ceil(revealVBytes * feeRate));
        const totalFee = setupFee + revealFee;
        const outputsValue = BigInt(outputCount) * HashCommitmentGenerator.MIN_OUTPUT_VALUE;
        const totalCost = totalFee + outputsValue;
        return {
            compressedSize,
            outputCount,
            chunkCount,
            setupVBytes,
            revealVBytes,
            setupFee,
            revealFee,
            totalFee,
            outputsValue,
            totalCost,
        };
    }
    hashChunk(data) {
        return crypto.hash160(data);
    }
    generateWitnessScript(dataHashes) {
        if (dataHashes.length === 0) {
            throw new Error('At least one data hash is required');
        }
        if (dataHashes.length > HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT) {
            throw new Error(`Too many chunks: ${dataHashes.length} exceeds limit of ${HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT}`);
        }
        for (const hash of dataHashes) {
            if (hash.length !== 20) {
                throw new Error(`HASH160 requires 20-byte hash, got ${hash.length}`);
            }
        }
        const scriptParts = [];
        for (let i = dataHashes.length - 1; i >= 0; i--) {
            scriptParts.push(opcodes.OP_HASH160);
            scriptParts.push(dataHashes[i]);
            scriptParts.push(opcodes.OP_EQUALVERIFY);
        }
        scriptParts.push(this.publicKey);
        scriptParts.push(opcodes.OP_CHECKSIG);
        return script.compile(scriptParts);
    }
    generateP2WSHAddress(witnessScript) {
        const p2wsh = payments.p2wsh({
            redeem: { output: witnessScript },
            network: this.network,
        });
        if (!p2wsh.address || !p2wsh.output) {
            throw new Error('Failed to generate P2WSH address');
        }
        return {
            address: p2wsh.address,
            witnessScript,
            scriptPubKey: p2wsh.output,
        };
    }
    prepareChunks(data, maxChunkSize = HashCommitmentGenerator.MAX_CHUNK_SIZE) {
        if (maxChunkSize > HashCommitmentGenerator.MAX_CHUNK_SIZE) {
            throw new Error(`Chunk size ${maxChunkSize} exceeds P2WSH stack item limit of ${HashCommitmentGenerator.MAX_CHUNK_SIZE}`);
        }
        if (data.length === 0) {
            throw new Error('Data cannot be empty');
        }
        const allChunks = [];
        let offset = 0;
        while (offset < data.length) {
            const chunkSize = Math.min(maxChunkSize, data.length - offset);
            allChunks.push(Buffer.from(data.subarray(offset, offset + chunkSize)));
            offset += chunkSize;
        }
        const outputs = [];
        let chunkIndex = 0;
        while (chunkIndex < allChunks.length) {
            const chunksForThisOutput = allChunks.slice(chunkIndex, chunkIndex + HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT);
            const dataChunks = chunksForThisOutput;
            const dataHashes = dataChunks.map((chunk) => this.hashChunk(chunk));
            const witnessScript = this.generateWitnessScript(dataHashes);
            const p2wsh = this.generateP2WSHAddress(witnessScript);
            outputs.push({
                address: p2wsh.address,
                witnessScript: p2wsh.witnessScript,
                scriptPubKey: p2wsh.scriptPubKey,
                dataHashes,
                dataChunks,
                chunkStartIndex: chunkIndex,
            });
            chunkIndex += chunksForThisOutput.length;
        }
        const totalChunks = allChunks.length;
        this.log(`Prepared ${outputs.length} P2WSH outputs with ${totalChunks} chunks ` +
            `(${data.length} bytes, ~${Math.ceil(data.length / outputs.length)} bytes/output)`);
        return outputs;
    }
}
HashCommitmentGenerator.MAX_CHUNK_SIZE = 80;
HashCommitmentGenerator.MAX_STACK_ITEMS = 100;
HashCommitmentGenerator.MAX_WITNESS_SIZE = 1650;
HashCommitmentGenerator.MAX_STANDARD_WEIGHT = 400000;
HashCommitmentGenerator.MIN_OUTPUT_VALUE = 330n;
HashCommitmentGenerator.BYTES_PER_COMMITMENT = 23;
HashCommitmentGenerator.SIG_CHECK_BYTES = 35;
HashCommitmentGenerator.WITNESS_FIXED_OVERHEAD = 1 + 73 + 3 + 35;
HashCommitmentGenerator.WITNESS_PER_CHUNK_OVERHEAD = HashCommitmentGenerator.MAX_CHUNK_SIZE + 1 + HashCommitmentGenerator.BYTES_PER_COMMITMENT;
HashCommitmentGenerator.MAX_CHUNKS_PER_OUTPUT = Math.floor((HashCommitmentGenerator.MAX_WITNESS_SIZE -
    HashCommitmentGenerator.WITNESS_FIXED_OVERHEAD) /
    HashCommitmentGenerator.WITNESS_PER_CHUNK_OVERHEAD);
HashCommitmentGenerator.INPUT_BASE_WEIGHT = 164;
HashCommitmentGenerator.INPUT_WITNESS_WEIGHT_MAX = HashCommitmentGenerator.MAX_WITNESS_SIZE;
HashCommitmentGenerator.WEIGHT_PER_INPUT = HashCommitmentGenerator.INPUT_BASE_WEIGHT +
    HashCommitmentGenerator.INPUT_WITNESS_WEIGHT_MAX;
